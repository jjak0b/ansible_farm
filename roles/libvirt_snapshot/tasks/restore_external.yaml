# These tasks simulate the behavior an internal snapshot restore but we need a VM restart to apply changes:
# - shutdown (eventually) the VM 
# - for each disk in the snapshot's domain: create a new overlay disk and set it as current disk in the VM with the snapshot's disk as its backingStore
# - edit the snapshot to restore by updating the overlay disks in use, and set it as current.
# - Restore the VM to the previous running state before the shutdown. ( note: this is just a poweron if it was running ).
# So the active disks will be the new overlay disks
# vars:
#   should_delete_dandling_overlays: (default: true)
#    - true if you want to delete the previous overlay image IF IT HAS NO DESCENDANTS SNAPSHOTS (that depends by the specified snapshot), otherwise will keep it anyway.
#    - false if you want to keep the dandling overlay image. Note that:
#      - the overlay reference on the provided snapshot to restore will be lost anyway, since a new overlay image will be created.
#      - this option should be only used if you want to manually re-use the dandling disk later for some reason.
#   should_restore_with_new_branch: (default: true)
#    - true if you want to restore to the snapshot and create an overlay branch and setting it as current snapshot overlay and use new overlay disks.
#    - false if you want to restore to the snapshot's domain (backing store domain), so after reboot the VM will use the backingStore disks as current disks.
---

- name: Check VM running state to restore
  community.libvirt.virt:
    command: status
    name: "{{ vm_name }}"
    uri: &libvirt_uri "{{ uri }}"
  register: vm_status_to_restore

- name: Dump VM xml at snapshot
  shell:
    cmd: >-
      virsh
      --connect {{ uri | quote }}
      snapshot-dumpxml
      --domain {{ vm_name | quote }}
      --snapshotname {{ snapshot_name | quote }}
  register: _snapshot_dumpxml_result

- name: Check descendants dependency
  shell:
    cmd: >
      virsh
      --connect {{ uri | quote }}
      snapshot-list
      --domain {{ vm_name | quote }}
      --from {{ snapshot_name | quote }}
      --descendants --name
  register: _snapshot_descendants_result
  changed_when: false

- name: Create temporary file to define the snapshot
  ansible.builtin.tempfile:
    suffix: "{{ snapshot_name }}.snapshot-dumpxml.xml"
    state: file
  register: _snapshot_dumpxml_file

- name: Restore Snapshot
  vars:
    # Note: don't use community.general.xml because for some reason it can't get the full xml tag associated to the xpath /domainsnapshot/domain, and output wrong data
    myParsedXMLSnapshot: "{{ ( _snapshot_dumpxml_result.stdout | ansible.utils.from_xml ) }}"
  block:

    - name: Init facts
      set_fact:
        domain_disks: []
        snapshot_disks: []
        new_overlay:
          name: "{{ vm_name }}.from_{{ myParsedXMLSnapshot.domainsnapshot.name }}_branch_{{ lookup('community.general.random_string', special=false ) }}"
          format: qcow2

    - name: Restore to backing store domain
      when:
        - not should_restore_with_new_branch
      block:

        - name: Select backing snapshot domain to restore
          set_fact:
            new_vm_domain_xml: "{{ myParsedXMLSnapshot.domainsnapshot | dict2items | selectattr('key', 'equalto', 'domain') | items2dict | ansible.utils.to_xml  }}"

        - name: Save unchanged snapshot domain into temporary file
          ansible.builtin.copy:
            dest: "{{ _snapshot_dumpxml_file.path }}"
            content: "{{ _snapshot_dumpxml_result.stdout }}"

    - name: Setup new branch
      when:
        - should_restore_with_new_branch
      vars:
        active_domain:
          disks: "{{ myParsedXMLSnapshot.domainsnapshot.domain.devices.disk is mapping | ternary( [ myParsedXMLSnapshot.domainsnapshot.domain.devices.disk ], myParsedXMLSnapshot.domainsnapshot.domain.devices.disk, [] ) }}"
      block:

        - name: "Foreach new disk source: Set new disk overlay and wrap the snapshot disk as its backingStore"
          loop: "{{ active_domain.disks }}"
          loop_control: 
            loop_var: disk
            label: "{{ updated_disk.backingStore.source[ '@file' ] | default( disk, true) }} -> {{ updated_disk.source[ '@file' ] | default( 'unchanged', true ) }}"
          set_fact: 
            # These are the disks that will be defined in the new VM domain
            domain_disks: "{{ domain_disks + [ disk | combine( updated_disk if disk.source | default(null, true) is defined else {}, recursive=true) ]  }}"
            # These are the disks that will be defined in the new snapshot domain
            snapshot_disks: "{{ snapshot_disks + [ snapshot_disk ] }}"
          vars:
            updated_disk:
              '@type': 'file'
              '@device': 'disk'
              backingStore:
                '@type': 'file'
                source: "{{ disk.source | default(null, true) }}"
                format:
                  '@type': "{{ disk.driver[ '@type' ] }}"
                backingStore: "{{ disk.backingStore }}"
              source: &disk_source
                '@file': "{{ ( disk.source[ '@file' ] | default('', true) | dirname, [ new_overlay.name, new_overlay.format] | join('.') ) | path_join }}"
              driver: &disk_driver
                '@type': "{{ new_overlay.format }}"
            snapshot_disk:
              '@name': "{{ disk.target[ '@dev' ] }}"
              '@snapsnot': 'external'
              '@type': file
              driver: *disk_driver
              source: *disk_source
        
        - name: "Foreach new disk source: create an overlay image with its backingStore"
          loop: "{{ domain_disks }}"
          loop_control:
            loop_var: disk
            label: "{{ disk.backingStore.source[ '@file' ] | default( disk, true ) }} -> {{ disk.source[ '@file' ] | default( 'unchanged', true) }}"
          when:
            - disk.backingStore | default( null, true) is defined
            - disk.source | default( null, true) is defined
          shell:
            cmd: >
              qemu-img create
              -f {{ new_overlay.format }} -F {{ disk.backingStore.format[ '@type' ] }}
              -b {{ disk.backingStore.source[ '@file' ] | quote }}
              {{ disk.source[ '@file' ] | quote }}
            creates: "{{ disk.source[ '@file' ] }}"
            
        - name: Save new snapshot domain into temporary file
          vars:
            snapshotChanges:
              domainsnapshot:
                disks:
                  disk: "{{ snapshot_disks }}"
          ansible.builtin.copy:
            dest: "{{ _snapshot_dumpxml_file.path }}"
            content: "{{ myParsedXMLSnapshot | combine( snapshotChanges, recursive=true ) | ansible.utils.to_xml }}"

        - name: Set new VM domain using the xml domain defined in the snapshot
          set_fact:
            new_vm_domain_xml: "{{ myParsedXMLSnapshot.domainsnapshot | combine( domainChanges, recursive=true ) | dict2items | selectattr('key', 'equalto', 'domain') | items2dict | ansible.utils.to_xml }}"
          vars:
            domainChanges:
              domain:
                devices:
                  disk: "{{ domain_disks }}"
      
      
      always:
        - name: clear facts
          set_fact:
            domain_disks: null
            snapshot_disks: null
            new_overlay: null
            backing_domain: null


      always:
        - name: clear facts
          set_fact:
            domain_disks: null
            snapshot_disks: null
            new_overlay: null
            backing_domain: null

    - name: Redefine VM using the new VM domain
      community.libvirt.virt:
        command: define
        xml: "{{ new_vm_domain_xml }}"
        uri: "{{ uri }}"
      register: snapshot_restore_result_external
    
    - name: Ensure to make VM domain changes effective
      vars:
        retry_count: 5
        retry_delay: 5
      block:
        - name: Ensure VM shutdown
          community.libvirt.virt:
            command: shutdown
            name: "{{ vm_name }}"
            state: shutdown
            uri: *libvirt_uri
          register: vm_stop_result
          retries: &shutdown_retries "{{ retry_count }}"
          until: &shutdown_until vm_stop_result is success and not(vm_stop_result is changed)
          delay: &shutdown_delay "{{ retry_delay }}"
      rescue:
        - name: Ensure VM is destroyed as fallback
          community.libvirt.virt:
            command: destroy
            name: "{{ vm_name }}"
            state: destroyed
            uri: *libvirt_uri
          register: vm_stop_result
          retries: *shutdown_retries
          until: *shutdown_until
          delay: *shutdown_delay
      always:
        - name: Update the new snapshot and set it as current
          shell:
            cmd: >
              virsh
              --connect {{ uri | quote }}
              snapshot-create
              --domain {{ vm_name | quote }}
              --xmlfile {{ _snapshot_dumpxml_file.path | quote }}
              --current
              --redefine
          register: snapshot_restore_set_active_result
      
        - name: Restore VM back to previous status
          vars:
            command_cases:
              destroyed: destroy
              running: start
              shutdown: shutdown
              paused: pause
          community.libvirt.virt:
            command: "{{ command_cases[ vm_status_to_restore.status ] | default(omit, true)  }}"
            name: "{{ vm_name }}"
            state: "{{ vm_status_to_restore.status }}"
            uri: *libvirt_uri
          register: _vm_restore_result
          until: _vm_restore_result is success and not(_vm_restore_result is changed)
          retries: *shutdown_retries
          delay: *shutdown_delay

        - name: clear facts
          set_fact:
            domain_disks: null
            snapshot_disks: null
            new_overlay: null
            new_vm_domain_xml: null

    - name: Remove dandling overlays
      loop: "{{ myParsedXMLSnapshot.domainsnapshot.disks.disk is mapping | ternary( [ myParsedXMLSnapshot.domainsnapshot.disks.disk ], myParsedXMLSnapshot.domainsnapshot.disks.disk, [] ) }}"
      loop_control:
        loop_var: dandling_disk
        label: "{{ dandling_disk.source[ '@file' ] | default( dandling_disk, true) }}"
      ansible.builtin.file:
        path: "{{ dandling_disk.source[ '@file' ] }}"
        state: absent
      when:
        - should_delete_dandling_overlays
        - not( _snapshot_descendants_result.stdout_lines | length > 0 )
        - dandling_disk.source[ '@file' ] | default(null, true) is defined
#     become: yes

- name: Remove temporary file
  ansible.builtin.file:
    path: "{{ _snapshot_dumpxml_file.path }}"
    state: absent
  when: _snapshot_dumpxml_file.path is defined


- name: set snapshot result
  shell: /bin/true
  register: snapshot_restore_result
  when: &on_success 
    - snapshot_restore_set_active_result is defined
    - snapshot_restore_result_external is defined
    - snapshot_restore_set_active_result is succeeded
    - snapshot_restore_result_external is succeeded
    - snapshot_restore_set_active_result.rc == 0
